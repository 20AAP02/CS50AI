_________Nim_________

Algorithm to use: 
	Reinforcement learning
		- Q-learning

(state, action)
- state: current size of all piles (ex: [1, 1, 3, 5])
- action: pair of integers, (i, j) : take 'j' objects from pile 'i'

Every time we are in state 's' and take an action 'a', we can update the Q-value 'Q(s, a)':
---  Q(s, a) <- Q(s, a) + alpha * (new value estimate - old value estimate) ---
alpha = learning rate (0 -> 1)
new value estimate = sum(reward received for the current action, estimate of all the future rewards)
old value estimate = existing value for 'Q(s, a)'

NimAI
self.q = {(state, action)  : number; (state, action)  : number}
state = tuple()
( ex: self.q[(0, 0, 0, 2), (3, 2)] = -1 )